## Introduction

Is poker a game of skill? Certainly it's a better game than chess for average people, because you can blame your losses on luck and get away with it. But what if you want to improve and get really good? Let's calculate that using a simulation.

I love chess and lichess. And I've always wanted a similar platform for poker. Poker but without the gambling and money. Just for viewing your stats and measuring your skill. My main concern is to draw attention and get people to actually spend their time on this poker site without actually gambling for money. My other concern is poker sites are illegal in my country.

One solution to draw attention is building an AI so it can play with the few people interested in the site to keep them entertained. In this article, I discuss my journey building a poker site, a poker playing AI using neural networks, and dealing with various challenges along the way.

In the past, I've studied how [lc0](https://lczero.org/) works, but never fully understood how the training data, weights of the network transferred between different systems and assembled. The C++ code was not implemented for tensorflow backend. Currently it is implemented, and now I have a more clear picture of how it works. Finally I will also share my conversations with ChatGPT that greatly speeded up my progress.

lc0 is an open source chess engine that uses Monte Carlo Tree Search and neural networks. It has two main parts, [the main engine lc0](https://github.com/LeelaChessZero/lc0), written in C++, is a UCI Chess Engine. Given a position, it starts a Monte Carlo Tree Search, and evaluates the leaf nodes by asking the neural network. The neural network is trained to take a position as input and output an evaluation that is a number. Actually there's more to it [as explained here in detail](https://lczero.org/dev/wiki/technical-explanation-of-leela-chess-zero/). Finally the main engine, also generates training data for the neural network to train. Training data consists of a position, and it's evaluation. This data is generated by the main engine by making the engine play a match between 2 MCTS. So MCTS uses the evaluation given by the neural network to generate the training data, that also consists of evaluation of a position, for the neural network. As the evaluation of a position gets more accurate through the MCTS, which means the quality of the training data gets more and more accurate. Considering the fact that in the beginning the evaluation of a position by the neural network was random. We will return to this later, now let's return back to poker.

## Poker Logic

Some considerations I took into account for building the poker logic.

Here's a representation of a round of poker: 
`10-20 1 | i80 AhAc / i180 2h2c / @280 3h3c $ 60-123 !f4h5h6h7h8h`

It consists of the information:

- `10-20` blinds, button is `Player 1`
- `Player 1` is in state `i` with `80 chips` with cards `Ah Ac`
- `Player 2` and `Player 3` are also in the hand
- `Player 3` has the action with 280 chips (`@280`)
- `60-123` 60 chips is already in the pot that both Player 1 2 and 3 can win.
- `f4h5h6h7h8h` we are on the flop (`f`) the board consists of cards `4h5h6h7h8h`.

Of course this information is on the server, the point of view of a player doesn't see the whole cards.

The players can be on various states like, "phase", "allin", "folded", "deal", "inthepot", "action", "showdown", "win".

The logic is carried out by one method `act(act: string)`. This accepts various dealer actions like 'deal', 'phase', 'showdown', 'share', as well as various player actions like 'check', 'call', 'fold', 'raise amount'. It doesn't check the validity of a given action, it just assumes it's valid and applies the logic. For example 'deal' action will deal the cards, post the blinds, and sets the player's states as "inthepot" and turn to act as "action". At various states of the simulation, the allowed actions (that can be passed to act method) can be queried by one getter method `.dests`. This will give you the allowed actions like dealer actions or player actions. It doesn't give you who's turn to act it assumes player actions are for the player who has the action.

Here's the first test that plays a round of poker between 3 players [https://github.com/eguneys/lheadsup/blob/master/tests/round2.test.ts#L492](https://github.com/eguneys/lheadsup/blob/master/tests/round2.test.ts#L492).

I've tried a few attempts at building the poker playing logic at [various times](https://github.com/eguneys/scalapoker). The [final version is here](https://github.com/eguneys/lheadsup).

Then there is also other details like building the pot and side pots, sharing the pots according to hands at showdown or the winner by others folding.

Finally the `act` method returns a list of events that describes the state changes for each player's point of view, which is hopefully will be used by the front end.

### The Cards and Poker Hands

The cards are represented as strings like this `Ah` for Ace of Hearts. The evaluation of poker hands uses [this article](http://nsayer.blogspot.com/2007/07/algorithm-for-evaluating-poker-hands.html) as reference.

## The Perfect Poker Strategy Playing AI

We will play a Headsup Texas Hold'em Poker Tournament. Because we need to establish a baseline for calculating the skills. To get close to chess, we establish a headsup tournament which is poker played by 2 players. Let's say best out of 11 matches. Each match, 2 players starts with some chips, only one player wins by winning all of other player's chips by playing a series of rounds. Each round players are dealt cards and poker is played as usual. To let the rounds eventually end, the blinds are increased every 10 rounds.

The exact numbers can vary, the goal is to limit the luck as much as possible to squeeze out the actual skill.

At various stages of development, I benchmarked and tested the poker logic and of course found out and worked on some bugs. So this work also acts as a stress test.

The simulation of this tournament is carried out by two "Poker Players". Player's take the state of the poker round by their point of view represented by the class `RoundNPov`, also the actions they are allowed to make called `Dests`. and return an action they want to make. Simulation plays the matches between players, on each match, gives each player a chance to make an action when it's their turn to move, and collects the statistics for the tournament.

So all there is left is to actually code the players. At this point I am also thinking about the website, if I can get a few interesting AI Players, I can challenge the users to play against these AI in the same headsup tournament style, and collect their statistics.

There are the simple strategies like as silly as like always folding, or more decent like always calling, always min raising, or going berserk like always going all in. Another strategy is the mix player that randomly selects one player to act like, so like playing randomly.

I built a benchmark that let's all players mash up and see how well they do against each other. The code is not well written but it's ok.

There is no clear strategy or tactics that can be applied in a game of poker, as opposed to chess. It is often mentioned that good players get an edge in the long term. But the "long term" is vague. From what I understand we can built 2 types of advanced poker strategy that would eventually gets an edge against simple strategies and hopefully against human players as well. One is the often mentioned "Game Theory Optimal" game play, this will make the decisions based on pot odds and the strength of the hand, and gets an eventual edge against deviating players in the long term. This type of play is called unexploitable solid play. The second and our ultimate goal with this project, is player will consider the history of the rounds, and hopefully actually exploit the various tendencies opponent makes. This assumption is the whole point of all the efforts we put into this AI project. I have played poker mostly for fun and trust in my decent skills, but I have no experience if this would actually work. 

## A Serious attempt at MCTS Poker AI

Now we enter the shady territory where ChatGPT sheds some light into our path.
The MCTS algorithm as implemented in lc0 is swarming with multithreading and more statistics and math that is difficult to understand. So my first attempt to mostly copy it partly failed. And there isn't clear cut, well defined MCTS algorithms on the internet. So I asked ChatGPT which it responded with a nice example implementation in Javascript. 


The actual MCTS after expanding a node that has no child, the value of the node is calculated by simulating a random playout starting from that node until the game ends, and using the game result as the value of the node. At first this gives a random result for the value of the node, considering the overall search the randomness is overcome by the number of iterations and giving more weight to promising children and eventually the best node will stand out. This is well explained by ChatGPT which there is a link to the conversation below. This algorithm forms the basis for our "Game Theory Optimal" Player.

Each node in MCTS is associated with a game position. A Node is terminal if the game position is an end situation. In chess this could be a checkmate or a stalemate. In our case in poker, a game position is a round of headsup poker where cards are dealt and it is a player to act, or a terminal situation where one player is about to collect the pot in a round. So one MCTS only cares about a single round of poker, where if it's player's turn to act it plays a move randomly otherwise it's a terminal situation where it evaluates the value of that situation. But this will change with our second type of player which we will come to later.

So our concern becomes how to evaluate the terminal situation of a poker round. Which is explained in detail [in this SO question on poker.stackexchange](https://poker.stackexchange.com/questions/12062/how-to-estimate-the-value-of-specific-end-round-situations-in-a-texas-holdem-he).


After working out the details of implementing this version, now I have a decent looking player using naive MCTS. Unfortunately I could only test against simple strategies I mentioned above. It gets even against always all in raiser, which probably could be improved with some tweaks. But I've tweaked it plenty already and don't want to spend more time on it as of now. I would get a better feel if I could play with it myself, which I plan to do after building a front end and an actual server that can host these tournaments.

As a side note, the MCTS folds plenty against always all in raiser, which goes allin preflop every hand. It calls with a pair of queens and probably some other pairs and folds Ace King. But I haven't tested throughly. Also it doesn't just blind out by folding, it calls an allin after getting below 2000 chips, which is a promising result. Although I am not sure if it actually is close to what I desired to accomplish as a "Game Theory Optimal" Player, I would probably get a better feel how strong, or at least interesting, it plays if I could play against it myself. It somewhat selects medium range raises which is considered interesting.

Now we turn our attention to the journey of our final goal, and see if we can get an edge against this version of naive MCTS Player.


## Interesting ChatGPT Conversations
- [MCTS in Javascript](https://chat.openai.com/share/d287c5d9-5060-4562-8ebd-653e4fc37cdd)
- [swarming word](https://chat.openai.com/share/180a4dd8-5592-4557-be0a-16816c8af838)
