## Introduction

Is poker a game of skill? Certainly it's a better game than chess for average people, because you can blame your losses on luck and get away with it. But what if you want to improve and get really good? Let's calculate that using a simulation.

I love chess and lichess. And I've always wanted a similar platform for poker. Poker but without the gambling and money. Just for viewing your stats and measuring your skill. My main concern is to draw attention and get people to actually spend their time on this poker site without actually gambling for money. My other concern is poker sites are illegal in my country.

One solution to draw attention is building an AI so it can play with the few people interested in the site to keep them entertained. In this article, I discuss my journey building a poker site, a poker playing AI using neural networks, and dealing with various challenges along the way.

In the past, I've studied how [lc0](https://lczero.org/) works, but never fully understood how the training data, weights of the network transferred between different systems and assembled. The C++ code was not implemented for tensorflow backend. Currently it is implemented, and now I have a more clear picture of how it works. Finally I will also share my conversations with ChatGPT that greatly speeded up my progress.

lc0 is an open source chess engine that uses Monte Carlo Tree Search and neural networks. It has two main parts, [the main engine lc0](https://github.com/LeelaChessZero/lc0), written in C++, is a UCI Chess Engine. Given a position, it starts a Monte Carlo Tree Search, and evaluates the leaf nodes by asking the neural network. The neural network is trained to take a position as input and output an evaluation that is a number. Actually there's more to it [as explained here in detail](https://lczero.org/dev/wiki/technical-explanation-of-leela-chess-zero/). Finally the main engine, also generates training data for the neural network to train. Training data consists of a position, and it's evaluation. This data is generated by the main engine by making the engine play a match between 2 MCTS. So MCTS uses the evaluation given by the neural network to generate the training data, that also consists of evaluation of a position, for the neural network. As the evaluation of a position gets more accurate through the MCTS, which means the quality of the training data gets more and more accurate. Considering the fact that in the beginning the evaluation of a position by the neural network was random. We will return to this later, now let's return back to poker.

## Poker Logic

Some considerations I took into account for building the poker logic.

Here's a representation of a round of poker: 
`10-20 1 | i80 AhAc / i180 2h2c / @280 3h3c $ 60-123 !f4h5h6h7h8h`

It consists of the information:

- `10-20` blinds, button is `Player 1`
- `Player 1` is in state `i` with `80 chips` with cards `Ah Ac`
- `Player 2` and `Player 3` are also in the hand
- `Player 3` has the action with 280 chips (`@280`)
- `60-123` 60 chips is already in the pot that both Player 1 2 and 3 can win.
- `f4h5h6h7h8h` we are on the flop (`f`) the board consists of cards `4h5h6h7h8h`.

Of course this information is on the server, the point of view of a player doesn't see the whole cards.

The players can be on various states like, "phase", "allin", "folded", "deal", "inthepot", "action", "showdown", "win".

The logic is carried out by one method `act(act: string)`. This accepts various dealer actions like 'deal', 'phase', 'showdown', 'share', as well as various player actions like 'check', 'call', 'fold', 'raise amount'. It doesn't check the validity of a given action, it just assumes it's valid and applies the logic. For example 'deal' action will deal the cards, post the blinds, and sets the player's states as "inthepot" and turn to act as "action". At various states of the simulation, the allowed actions (that can be passed to act method) can be queried by one getter method `.dests`. This will give you the allowed actions like dealer actions or player actions. It doesn't give you who's turn to act it assumes player actions are for the player who has the action.

Here's the first test that plays a round of poker between 3 players [https://github.com/eguneys/lheadsup/blob/master/tests/round2.test.ts#L492](https://github.com/eguneys/lheadsup/blob/master/tests/round2.test.ts#L492).

I've tried a few attempts at building the poker playing logic at [various times](https://github.com/eguneys/scalapoker). The [final version is here](https://github.com/eguneys/lheadsup).

Then there is also other details like building the pot and side pots, sharing the pots according to hands at showdown or the winner by others folding.

Finally the `act` method returns a list of events that describes the state changes for each player's point of view, which is hopefully will be used by the front end.

### The Cards and Poker Hands

The cards are represented as strings like this `Ah` for Ace of Hearts. The evaluation of poker hands uses [this article](http://nsayer.blogspot.com/2007/07/algorithm-for-evaluating-poker-hands.html) as reference.

## The Perfect Poker Strategy Playing AI

We will play a Headsup Texas Hold'em Poker Tournament. Because we need to establish a baseline for calculating the skills. To get close to chess, we establish a headsup tournament which is poker played by 2 players. Let's say best out of 11 matches. Each match, 2 players starts with some chips, only one player wins by winning all of other player's chips by playing a series of rounds. Each round players are dealt cards and poker is played as usual. To let the rounds eventually end, the blinds are increased every 10 rounds.

The exact numbers can vary, the goal is to limit the luck as much as possible to squeeze out the actual skill.

At various stages of development, I benchmarked and tested the poker logic and of course found out and worked on some bugs. So this work also acts as a stress test.

The simulation of this tournament is carried out by two "Poker Players". Player's take the state of the poker round by their point of view represented by the class `RoundNPov`, also the actions they are allowed to make called `Dests`. and return an action they want to make. Simulation plays the matches between players, on each match, gives each player a chance to make an action when it's their turn to move, and collects the statistics for the tournament.

So all there is left is to actually code the players. At this point I am also thinking about the website, if I can get a few interesting AI Players, I can challenge the users to play against these AI in the same headsup tournament style, and collect their statistics.

There are the simple strategies like as silly as like always folding, or more decent like always calling, always min raising, or going berserk like always going all in. Another strategy is the mix player that randomly selects one player to act like, so like playing randomly.

I built a benchmark that let's all players mash up and see how well they do against each other. The code is not well written but it's ok.

There is no clear strategy or tactics that can be applied in a game of poker, as opposed to chess. It is often mentioned that good players get an edge in the long term. But the "long term" is vague. From what I understand we can build 2 types of advanced poker strategy that would eventually gets an edge against simple strategies and hopefully against human players as well. One is the often mentioned "Game Theory Optimal" game play, this will make the decisions based on pot odds and the strength of the hand, and gets an eventual edge against deviating players in the long term. This type of play is called unexploitable solid play. The second and our ultimate goal with this project, is a player that will consider the history of the rounds, and hopefully actually exploit the various tendencies opponent makes. This assumption is the whole point of all the efforts we put into this AI project. I have played poker mostly for fun and trust in my decent skills, but I have no experience if this would actually work. 

## A Serious attempt at MCTS Poker AI

Now we enter the shady territory where ChatGPT sheds some light into our path.
The MCTS algorithm as implemented in lc0 is swarming with multithreading and more statistics and math that is difficult to understand. So my first attempt to mostly copy it partly failed. And there isn't clear cut, well defined MCTS algorithms on the internet. So I asked ChatGPT which it responded with a nice example implementation in Javascript. You can find the conversation at ChatGPT section at the bottom.


The actual MCTS, after expanding a node that has no child, the value of the node is calculated by simulating a random playout starting from that node until the game ends, and using the game result as the value of the node. At first this gives a random result for the value of the node, considering the overall search the randomness is overcome by the number of iterations and giving more weight to promising children and eventually the best node will stand out. This is well explained by ChatGPT which there is a link to the conversation below. This algorithm forms the basis for our "Game Theory Optimal" Player.

Each node in MCTS is associated with a game position. A Node is terminal if the game position is an end situation. In chess this could be a checkmate or a stalemate. In our case in poker, a game position is a round of headsup poker where cards are dealt and it is a player to act, or a terminal situation where one player is about to collect the pot in a round. So one MCTS only cares about a single round of poker, while simulating a playout where if it's player's turn to act it plays a move randomly otherwise it's a terminal situation where it evaluates the value of that situation. But this will change with our second type of player which we will come to later. Note that we quickly skip the dealer actions by applying them in the playout.

So our concern becomes how to evaluate the terminal situation of a poker round. Which is explained in detail [in this SO question that I asked on poker.stackexchange](https://poker.stackexchange.com/questions/12062/how-to-estimate-the-value-of-specific-end-round-situations-in-a-texas-holdem-he).


After working out the details of implementing this version, now I have a decent looking player using naive MCTS. Unfortunately I could only test against simple strategies I mentioned above. It gets even against always all in raiser, which probably could be improved with some tweaks. But I've tweaked it plenty already and don't want to spend more time on it as of now. I would get a better feel if I could play with it myself, which I plan to do after building a front end and an actual server that can host these tournaments.

As a side note, the MCTS folds plenty against always all in raiser, which goes allin preflop every hand. It calls with a pair of queens and probably some other pairs and folds Ace King. But I haven't tested throughly. Also it doesn't just blind out by folding, it calls an allin after getting below 2000 chips, which is a promising result. Although I am not sure if it actually is close to what I desired to accomplish as a "Game Theory Optimal" Player, I would probably get a better feel how strong, or at least interesting, it plays if I could play against it myself. It seldom selects medium range raises which is considered interesting.

Of course this has no concept of bluffing or slow playing, or playing the player, now we turn our attention to the journey of our final goal, and see if we can get an edge against this version of naive MCTS Player.

## Journey for Reinforcement Learning Self Playing Poker AI

Before we begin, we start with warmup tasks.

There is one bottleneck with the naive MCTS Player we mentioned in the previous chapter.

 `let strength = ehs(round.stacks[0].hand!, middle)`

The strength of the hand is calculated by simulating 50 iterations of possible outcomes and returning the ratio of winning. This is slow as it evaluates the poker hand, which is already not a well optimized function, on each iteration. So this drastically slowed down the benchmarks.

One challenge with using neural networks, at least for a beginner, is it consists of two parts. One part is training, the second part is predicting. And training and predicting is implemented separately on different programming languages. Training will be done in Python, predicting will be done in Javascript (lc0 uses C++). Tensorflow.js helps with this as it provides the same Tensorflow API as Tensorflow API for Python. Still I am not exactly sure if it will behave the exact same way as there are a lot of calculations done on various dimensions. Also the input data needs to be encoded the same in both versions. Finally there is the challenge of transfer of weights (that is as we refer to as the network itself). Which is not clearly explained in the docs. 

Hopefully the leela zero codebase acts as a solid reference, which explains everything precisely in code, the docs, and ChatGPT makes this job a lot easier.

### Task #1 Label the Poker Hands

So for starters, I thought I would rank a poker hand, which consists of 5 cards (actual poker hand is 5 cards that makes the best hand out of 7 cards), like high card with A kicker, pair of Aces, 2 pair with Ace and 2, a set, a flush etc.
So I mostly copied the code from [lc0-training](https://github.com/LeelaChessZero/lc0), adapting to our specific task, which is simpler and means less code.

To summarize what is happening: 

- A config file which some parameters are specified. 
- The training data that is split into lots of separate gzipped files called chunks. That consists of like 10k samples of data.
- A chunk parser that parses chunks of gzipped training data and generates batches of input for consuming by a Tensorflow Dataset.
- Two of these chunk parsers one for training and one for testing.
- Two Tensorflow Datasets that uses two chunk parsers each (passes the batches of input generated by chunk parser into the Tensorflow model).
- A TFProcess class that builds the model, restores from a checkpoint, runs the training loop for some number of steps, saves the model's weights into a file.


### Task #2 Evaluate the Hand Strength

As mentioned previously this function is slow as is currently used, so we will attempt at calculating this faster using neural networks.

This is a simplified version of algorithm explained [in this wiki article](https://en.wikipedia.org/wiki/Effective_hand_strength_algorithm). At 4 phases of a poker round, preflop, flop, turn and river, player has two cards at hand, and 5 cards on the board are revealed in each phase. So given total of 7 cards, a player makes up his hand by selecting 5 cards that makes up the best hand. But hand strength takes into account not only unrevealed cards on the board, but also the opponents two cards that might possibly beat player's own hand also using the board. Thus the hand strength is calculated by simulating possible cards that are unknown by random selection 50 times and calculating the win ratio against those simulations.

The best thing about this task is we can generate as many data samples as we like without dealing with noise or inaccurate data. The downside is it's a little slow. All we have to do is generate 7 cards randomly calculate the hand strength, use this as one sample out of 10k samples, and pack this into one gzipped chunk of data, and do this 100 times, to get one million samples.

The input to the model is slots for 7 cards 5 of them could be empty if it's on preflop phase, and all of them are filled on the river phase. Through some iterations, I figured I would get more accurate results if I built separate networks for each phase of the game, and use the according network on each specific phase. And the input encoding and network architecture doesn't have to change on any of the networks, we just train them on specific samples of data taken from that specific phase. Like river network would train with data that has all card slots filled, and preflop phase would train with data that has only 2 card slots filled.

As a beginner who have never done this before, I expect to get useful results as this is a lot similar to a simple image recognition task. Though, naturally not only you need to consider the hand you have made like two pair, one pair, high card, straight etc, but you also have to consider the possiblity of your opponent making a higher hand like, if there are 4 clubs on the board, it is more likely your set (which is normally very strong on headsup poker), might be beaten, so greatly reduces the common strength of your hand. Of course none of this logic matters to a neural network, as I am not exactly sure how it works in it's intricate details.


I was feeling good when the value I get from the Accuracy metric on training in Python finally matched the model I built on Javascript. But it took a while of debugging to get there. But from that point on, I knew all I had to worry about was actually training a good network.

The model is training as this article is being written. But currently I couldn't pass 80% accuracy on test set, which is even lower as 70% on random hand data. 

Here are some pretty stats I print for various networks:
(A is accuracy, O is outliers)
```
ehs1_river_0x16-108000 A: 0.43 O: 0.22
ehs1_river_0x16-36000 A: 0.31 O: 0.37
ehs1_river_1x32-36000 A: 0.59 O: 0.13
ehs1_river_3x32-100000 A: 0.58 O: 0.12
ehs1_river_3x32-50000 A: 0.76 O: 0.05
ehs1_river_6x64-108000 A: 0.74 O: 0.06
```
Accuracy is the ratio of number of accurate samples that is output with a difference less than 0.09 than the target.
Outlier is the ratio of number of outlier samples that is output with a difference greater than 0.2 than the target.
Note that Output is the hand strength value in 0-1 range.

`3x32` means 3 residual blocks and 32 filters. `50000` means it is trained for 50000 steps.

`3x32` network performs x6 faster than naive calculation so that's a plus. Though the real benefit of this experiment is that we actually built a working example of a neural network that we can use with a certain level of error.

Tackling with our real challenge, now we are more experienced.


## Interesting ChatGPT Conversations
- [MCTS in Javascript](https://chat.openai.com/share/d287c5d9-5060-4562-8ebd-653e4fc37cdd)
- [swarming word](https://chat.openai.com/share/180a4dd8-5592-4557-be0a-16816c8af838)
